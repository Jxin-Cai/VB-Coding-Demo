1.近期为几个IT团队做过效能提升的咨询。技术领导们都有个KPI--效能提升+裁员一定比例。简单说就是AI+后研发团队的产出要提高，成本要降低。但到底该怎么提高？简单说无非就是一个人做要更多的事，但一个人要怎么做更多的事呢？以下给出看到的几种实践路线，以及相关的可行方案以及方案的优缺点。

2.第一种，一个人做多个角色的事情。我们都知道软件工程很大一部份成本都在沟通上，各种会议各种文档都是因为有不同角色要做不同的事情，然后角色与角色之间要交接工作产生的。那如果一个人可以做多个角色的事情，那就能干掉这份沟通成本，而且还能保证需求不失真。

一个人做软件研发过程所有角色，比如用bmad框架来进行软件研发工作。这个的本质相当于有一个专业的软件工程团队。包括 BA（商业分析师） PM（产品经理） UX（体验设计师） EA/AT(架构师) QA（测试） SM（敏捷教练） DEV（研发工程师），来为你提供咨询规划到交互落地的全链路工作。帮助你把愿望用一定套路变成落地的软件。

bmad安装和初始化文档：
可以查看该网址获得：https://github.com/bmad-code-org/BMAD-METHOD

bmad使用步骤：
1.workflows/workflow-init 初始化整个工作流（工作流监控会话）2.新启会话切换到 BA/Analyst（商业分析师会话），和他 workflows/brainstorming 头脑风暴工作坊，确定目标。让其执行 workflows/research 进一步完善目标， 执行 workflows/create-product-brief 明确产出 需求调研文档，用于后续角色的工作。3.切回（工作流监控会话） workflows/workflow-status 查看当前任务执行状态，并基于提示开始后续工作4.新启会话切换到 PM（产品经理会话），执行 /workflows/prd 流程，开始基于需求调研结果生成完整的PRD文档。5.切回（工作流监控会话） workflows/workflow-status 查看当前任务执行状态，并基于提示开始后续工作。6.新启会话切换到UX（体验设计会话），执行/workflows/create-ux-design ,开始基于产品PRD生成对应的UX设计文档，包含交互流程和原型图和用户画像和用户旅程（与用户交流产出，大概有13-15步，1个多小时）。7.切回（工作流监控会话） workflows/workflow-status 查看当前任务执行状态，并基于提示开始后续工作。8.新启会话切换到EA/Architect（架构师会话），执行 workflows/create-architecture 开始创建架构设计文档，会基于UI设计和产品PRD来做架构设计，具体的技术先选型和用户沟通得出。（已有项目可能还得执行 workflows/generate-project-context 摸一下项目现状）9.切回（工作流监控会话） workflows/workflow-status 查看当前任务执行状态，并基于提示开始后续工作。10.切回到 PM（产品经理会话），执行 /workflows/create-epics-and-stories 流程，开始基于架构设计 PRD 体验设计文档，开始拆epics。11.切回（工作流监控会话） workflows/workflow-status 查看当前任务执行状态，并基于提示开始后续工作。12.新建 QA/TEA （质量保障会话）,执行 workflows/testarch-test-design 开始基于上述的文档创建UC测试用例集13.切回（工作流监控会话） workflows/workflow-status 查看当前任务执行状态，并基于提示开始后续工作。14.切回EA/Architect（架构师会话），执行workflows/check-implementation-readiness做实现前的检查，并修复问题。16.切回（工作流监控会话） workflows/workflow-status 查看当前任务执行状态，并基于提示开始后续工作。17.新建 SM（敏捷教练会话），执行 workflows/sprint-planning 做迭代计划。 执行 workflows/create-story 为每个迭代创建故事卡。18.切回（工作流监控会话） workflows/workflow-status 查看当前任务执行状态，并基于提示开始后续工作。19.新建DEV（研发工程师会话），执行 workflows/dev-story 开始逐个实现故事卡&包含了前边测试案例的测试验证。执行 workflows/code-review 检查是否符合代码规范。20.切回（工作流监控会话） workflows/workflow-status 查看当前任务执行状态，并基于提示开始后续工作。21.切回EA/Architect（架构师会话） ，执行 workflows/code-review 检查是否符合规范。

![BMAD方法完整工作流程](./flowcharts-obsidian/01-bmad-workflow.png)

好处，定义的AI角色几乎可以等于该角色的专家从业人员。发现问题的专业角度，提出的建议都是专家级别的。同时还有工作流和生成文档模版的辅助。工作流相当于把该角色原本工作的SOP和套路，固化成了工作流，这样能保证工作产出的稳定性和准确性。文档模版也能让工作产出方向更聚焦，让下一个角色更清楚如何获取需要的信息。

弊端：时间长，生成无法符合预期。 因为是真的把现实的流程1:1照搬进来，所以沟通就非常细致，随便开发个什么小玩意都要5-6小时起步。 沟通细致产出的文件也很细致。导致后续角色虽然独立的会话窗口，但依旧会因为上下文太大而丢失部分信息，导致偏离一开始的目标。最终生成的效果和预期不符，可能服务都启动不起来。

个人见解：
我自己因为职业特性，切身经历了软件研发，从规划->需求调研->产品设计->架构设计->交付->敏捷迭代的完整流程。和对应的所有角色都有深入的合作。所以也能感知套这套流程的完整和欠缺。 完整度相信大家也能看出来。我们提提欠缺的。1.头脑风暴这个，这个的本质是集合大家（业务专家）的智慧来得出结论，它需要发散思维（把不同角色想到的内容的贴墙上），和达成一致（合并认知在一次会议拉起概念和目标）。自己跟自己头脑风暴始终是片面的。2.产品经理拆故事卡，一个功能的效果和其实现的逻辑其实还是有差异的。很多时候实现的逻辑需要研发TL来补充信息。而在这套流程里边是仅产品经理侧的拆故事卡。这样出来的故事卡给到研发同学倒也没问题，因为研发只要理解意图就会自己补其如何实现的问题。但AI不是研发同学，它的本质还是单词接龙。仅表明意图的故事卡其实现就会波动，有时波动到正确的路径，但更多的时候是错误的，或一点点或大错特错。（意图：提供一个捞出用户拥有的所有角色的展示接口。 实现：使用consultants 走关联表 实现：使用consultants_openrole + openrole表捞出实现consultant的所有openrole的name）（bmad在固化真实的软件研发过程，但真实的软件研发过程不等于AI好理解的软件研发过程，其产出物本来就是给人解读的，而不是给AI）3.上诉的问题导致研发同学不得不review生成的epic和故事卡，并加以补充和修改。但dev这里又不再区分，dev可以做所有实现相关的事情。现实中我们分成前端，后端，测试，运维这些偏实现的技术角色，本质上是这里负责的软件研发过程的链路不同，关注的内容不同，需要的技术栈也不一样，而这里的认知差异足够区分出多个角色来。通常国内我们也能看到后端不限语言，来了可以学，但已经很少说前端也能来，然后转后端这样。因为这里边已经不是单纯的语言这个东西，还有语言背后的庞大社区 编程范式 最佳实践等等。所以资深前后端很难互转（相互写写业务代码，改改bug还行，但很难做制定规范，写框架core代码等等需要更多认知的事，资深后端转前端直接变成初级）。同样的，换到AI辅助编程的时代，语法不懂AI可以解读，不知道在哪里加功能 AI也能定位和代劳，似乎我们只要能看懂自然语言的逻辑，就能无视语言体系去迭代开发。但实际上自然语言表达的逻辑只是代码的一部分，框架的使用，各种非功能性的问题就全靠AI能不能考虑到了。这样的实践就很容易把bug带到生产。所以即便只是dev侧的全栈开发，似乎也只有 2B的小项目能够享受这个效率提升。一旦对生成容错低的，其实直接让开发同学全栈开发还是很危险的。也看到过好几例出问题的，比如产品经理写前端，出bug处理不了还得找前端同学帮忙，前端同学得重头看AI写的代码，然后一边骂一边皱着眉头删掉。比如，后端同学直接全栈开发，前端的某个交互样式，死活实现不出来，反复的给AI描述想要的效果，但AI就像卡住了一样，换着实现，但都与预期不一样。比如，java后端写ruby，逻辑都对，框架使用有问题，埋下了极端场景会死循环的bug等等。4.配置的内容细本身不是问题，先把配置柔细，后边再玩约定大于配置或者方案组合来提效就好。问题是好多细的内容都有点莫名其妙。比如我做一个面向C端主打体验的app，那可能字体就很重要。但我就做一个工作，一直让我抠字体抠样式就很扯，一个工具，实现功能才是最大的价值。5.比较突出的优点，planning-with-files做的比较好，能知道执行到哪了，并继续工作。唯一一个涵盖软件研发全流程的框架，其他框架大多都是从交付阶段开始，顶多在交付阶段前在加一点“需求讨论”。

3.第二种，一个人做同时做多个需求。这个基本已经都这样了。AI辅助编程已经可以生成较大的需求，那么在生成需求的这段时间自然可以做别的事情，所以很自然就可以并行开发多个需求。
这里有个特殊case，假设要在同个项目同时开发多个功能。因为git只能切一个分支开发，所以可能就得复制多个代码仓在不同目录，然后分别在这些目录切分功能分支进行开发。这个做法其实也还好（同个项目并行开发的场景还是比较少，哪怕有，并行2-3个也顶天了），但是不够便捷。更好的做法是借用 worktrees 来实现并行开发多个功能。 比如 最近比较火的 superpowers 就把 worktrees 融合到它的流程中去。

superpowers安装和初始化文档：
https://github.com/obra/superpowers/tree/main

superpowers 的执行步骤

1. Brainstorming（头脑风暴 / 需求分析）
   内容：苏格拉底式对话提炼需求
2. Git Worktrees（创建隔离工作区）（/superpowers:using-git-worktrees）(需要注意看，有时候会没执行/superpowers:using-git-worktrees，需要介入下)
   内容：新分支 + 环境验证
3. Writing Plans（编写实施计划）（技术栈 API 数据模型 核心组建 核心流程 项目架构）（superpowers:writing-plans）
   内容：2-5 分钟粒度的任务
4. Subagent Dev（子代理驱动开发，隔离上下文）
   （可以选择 A. Subagent-Driven（当前会话） │ 我逐任务派发子代理执行，每个任务后进行代码审查，快速迭代） B. Parallel Session（独立会话） │ 你在 worktree 中开启新会话，使用 superpowers:executing-plans 批量执行
   内容：每任务派遣新子代理；两阶段审查
5. TDD Cycle（测试驱动开发）
   内容：RED → GREEN → REFACTOR；先写测试，后写代码
6. Code Review（代码审查）
   内容：规格合规 + 代码质量；关键问题阻止进度
7. Debugging（系统化调试）
   内容：4 阶段根因分析；先找根因，再修复
8. Verification（验证完成）
   内容：确保真正修复；所有测试通过
9. Finish Branch（完成分支）（superpowers:finishing-a-development-branch）
   内容：合并 / PR / 保留 / 丢弃；清理工作树

![Superpowers敏捷开发流程](./flowcharts-obsidian/02-superpowers-workflow.png)

superpowers 的操作步骤 1.执行 /superpowers:brainstorm + 需求描述或需求文档。 其余就看提示交互了 2.头脑风暴完如果没有提示 /superpowers:using-git-worktrees , 一定要手动执行。不然会自己把更新提交到main分支上，和别人的提交重叠后回退会麻烦。

好处，简洁高效，用户只需聚焦在前期的需求的澄清和方案选型。不需要讨论很多细节。bmad像是为每个课题0-1配置出一个方案，superpowers则是提供几种最优方案给用户选择。弊端：并没有严格的planning-with-files，仅仅只有plan输出一个文件，并且这个文件还不全，很多决策在会话里边。其他的任务拆分，以及执行都是在会话中完成（分发给子agent也算）。所以对于任务中断不好续传，容易产生混乱。网络不好，重新执行时甚至可能出现比较离谱的问题，比如合并 worktree 时，把前端代码都丢失了，只合并了后端代码。同时因为都是给现成方案，对于用户甚至可能不知道提那些改进意见，导致生成的效果符合方案预期，但不一定符合用户预期。比如bmad的UX设计会细到包括字体的设计，而superpowers就完全没有这些选项，甚至页面的主题，交互的形式都很少会提及，更多还是完成功能的逻辑性的设计。全按照选项生成的方案到落地效果很好，但如果提出大量的非选项调整，被调整完整个方案与调整部分的集成容易缺胳膊少腿，导致生成有bug。比如当我发现类目和文件都要做排序和层级管理，提议抽一个公共的模块来管理资源的层级和排序，以便于两个资源复用。模块本身的开发没问题，但各个资源使用该模块的相关逻辑却有缺漏。

但不管是给用户提供最佳实现方案，还是后边独立上下文的subagent和TDD实现功能，都使得生成效果高效且稳定。
但并不推崇这种同个项目并行迭代的方式。当我们使用 superpowers 这种SDD框架，其实方案什么的已经慢慢把控不了太细节了，生成的代码更是大部分都不怎么看。这时候你要去合并分支处理冲突其实是有一些吃力的。处理冲突的时间，可能串行跑2 3次澡搞定了。
总的来说，针对大的端到端功能，生成算是比较稳定的。但比较不好定制，做做demo的效果很惊艳。不看方案和代码实现很可能是未来的主线，但现在走这种模式意味着不可控，意味着功能的实现像炼丹，逻辑正确，但样式 交互 非功能性需求设计就全看运气了。

4.第三种，一个人做更长时间的事情，早上搞方案，晚上跑代码，24小时工作。这一块，早些时候大家一直在关注 ralph-wiggum:ralph-loop和OMO这些框架，因为他们有个相同的特点，会驱动会话一直交互直到完成，而不是有点问题就中断，或者做一半就中断，以此来保证持续长时间的运行。大量需求 + 不中断的执行，就可以保证晚上一直生成，把晚上的时间用上。但其实这里边的关键不是不中断的执行，而是生成的质量高。不然比如你做一晚上生成了10个需求，但其中有1个有bug，假如AI自己没修好，你可能得花一整天时间来寻找并修复这个bug。这就有点像买了3D打印机，反正不能让 3D打印机歇着，24小时都得运作。一直使用大佬的高质量模型文件（高质量的方案设计），打印很稳定，第二天起来成品没有问题，或者也只是一些小瑕疵无伤大雅（没有bug，或者就一些小bug，丢给AI交互几轮就修复了），那就可以很愉快的24小时工作。但如果使用的是菜鸟的模型文件(切片没做好)（低质量的方案设计），打印很不稳定，设置完打印，去睡觉，可能打印没多久模型就倒了（出现bug），然后开始炒面，浪费耗材浪费电（浪费token浪费电）。那别说24小时运作了，恨不得直接把机器退了。更或者，打印用的是官方的耗材(C4.5/GPT5.2)，那打印稳定，机器的状态也好。但为了图便宜（量大管饱）使用非官方的耗材（DS/GLM/MIMO/千问），那就难免要偶尔打印失败几次（出现bug），机器堵头几次（和AI IDE适配不好，导致使用框架交互有bug，需要自己追加一些提示词来纠偏）。更或者B家的打印机用A家的耗材（反重力用C4.5），B家的打印机用A家的切片模型文件（opencode 集成 superpowers<superpowers还是在CC最稳定>），也可能打印出bug（一直交互报agent错误）。

ralph-wiggum:ralph-loop就CC的一个插件，正常安装就好。 使用也没有任何成本：
执行： /ralph-loop "Your task description" --completion-promise "DONE" 就好。

OMO安装
https://raw.githubusercontent.com/code-yeongyu/oh-my-opencode/refs/heads/master/docs/guide/installation.md
OMO使用：

OMS和BMAD有点像，也会圈定一些角色，形成一个团队，然后按一定流程去驱动这些角色执行工作。只是这些角色不是传统的软件工程的角色。而是站在当代VB coding的角度，经常需要AI执行哪些繁重的任务来设计的角色。同时也不是一条死的工作流 而是由 agent Sisyphus 驱动的智能流转持续运作直到产出结果的智能任务决策。
大致角色如下：

1. Sisyphus (调度者)
   模型：anthropic/claude-opus-4-5
   角色：默认智能体，强大的 AI 编排者。负责规划、委派和执行复杂任务。
2. Oracle (架构师)
   模型：openai/gpt-5.2
   角色：架构设计、代码审查、战略制定。拥有卓越的逻辑推理能力。
3. Librarian (Doc文档RAG)
   模型：anthropic/claude-sonnet-4-5
   角色：官方文档查询、开源实现分析、代码库深度探索。
4. Frontend UI/UX Engineer
   模型：google/gemini-3-pro-high
   角色：设计师出身的开发者。构建华丽、富有创意的 UI。
5. Explore (Code Scout)
   模型：opencode/grok-code
   角色：闪电般快速的代码库探索和模式匹配。6.其他（角色都是插拔的，后续还可以便捷增加）

![OMO框架 - Sisyphus智能调度流程](./flowcharts-obsidian/03-omo-sisyphus-workflow.png)

使用只需要在需求描述前加一个 ulw 关键字就好。可以说是相当的无脑。

内部执行的一些优化点：

1.多模型智能协同（Multi-Model Orchestration）(根据每个模型专长来匹配对应的角色执行任务，角色间上下文隔离)
GPT 5.2 (Oracle) → 架构设计、复杂 Debug
Gemini 3 Pro → 前端 UI/UX 视觉设计
Claude Sonnet → 文档研究、OSS 分析
Grok/Flash → 快速探索，成本几乎为零

2.任务完成保证机制（Task Completion Guarantee）
Todo Continuation Enforcer 强制监控
Ralph Loop 持续执行直到完成
验证循环：执行→诊断→测试→确认
核心哲学："无证据 = 未完成"

3.智能上下文管理（Intelligent Context Management）
Preemptive Compaction (85% 自动压缩)
AGENTS.md 自动注入项目规则
Notepad 系统跨会话持久化学习
动态截断防止单次搜索耗尽上下文

4.💎 代码质量保护（Code Quality Protection）
Comment Checker 防...（内容截断）
禁止 @ts-ignore / as a
防止AI生成过量注释

等等

个人评价：效果还是比较惊艳的。生成的东西该有的都有。但是就是太烧token了，有种 token + 时间 换生成质量的感觉。同时因为充分使用多个模型的伟大设计，使用者要想体验不得不买多个模型厂商的plan，着实有点坑，普适性大大受影响。（虽然可以直接买中转站的方式来实现，但这个设计使用的前置条件依旧忍不住吐槽下）。问题和superpowers也相似，没啥插手的地方，生成除了逻辑外其他靠运气，纯炼丹，只是这个成单率相交之前除暴的自己构建提示词走工作流高出太多。

综上所诉，到底哪个方向是未来的主流方向？不知道，可能都是，也可能还会冒出别的，毕竟现在的技术迭代日新月异。哪个框架工具最好用。也不好说，都在持续迭代各有各的使用场景和配套。比如用cursor的可能主要还是 speck-kit openspeck这些，毕竟cursor本身就做了一些生成增强，叠加其他机制更完整的，时长有冲突，可能还不如纯 vb coding。OMO目前只在opencode上用。superpowers虽然支持了好几家，但只有CC交互是最稳定的。但有哪些最佳实践还是能总结的：1.重方案轻代码生成（工作重心在前期的方案设计）
2.RAG 生成项目信息 + 浏览外部信息等等获取高质量信息来增强生成的手段3.方案要拆分多个有限大小的任务来执行，执行要走subagent（上下文隔离）
4.skills 便于沉淀提效小单元，实现复利。学习成本低，方便其他人加入，使用和做增强。
5.planning-with-files 借助文件固化方案和工作流进展。方便查看/协作/切换终端/断点续传。
6.TDD依托测试来驱动功能逐步生成
7.worktrees 并行干多件事，或者并行炼丹跑马出最优方案（token换生成质量）。
8.loop循环执行到最终完成

还能看到一个趋势，当前火的框架相交之前，人工介入的机会和成本都大幅降低。代码生成降低对人这个个体的依赖是必然的趋势。实现就是闭眼炼丹，好坏可以靠炉子自己的运作机制(不同的SDD框架)+材料的好坏(LLM本身的提升)来提升，也可以靠多高几炉取最好来提升。
