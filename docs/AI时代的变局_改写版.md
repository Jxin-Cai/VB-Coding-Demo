# 当AI成为队友，我却成了系统的Bug

## 一个主程的困境

去年，我遇到了一件很荒谬的事。

那段时间我在一个项目上做主程，兼着TL的活。项目氛围挺微妙的——大家都知道行业不景气，裁员的传闻满天飞，团队里弥漫着一股"等礼包"的气氛。没人有激情，大家都在混日子，而我作为老人，却要保证每个人都有活干，保证项目按时交付。

这时候，Claude 4.0发布了。

我是那种喜欢折腾新技术的人，从3月份Claude 3.7开始就在用AI写代码。到了5月份4.0发布的时候，我已经完全适应了这种工作方式——不再自己写代码，而是和AI对话，让它帮我实现。效率确实提升了很多，一个人能顶以前两三个人的产出。

但问题来了。

按照惯例，我会写故事卡、做技术方案，然后把任务分给团队成员。可现在的情况是，当我和AI把方案做出来后，生成代码就只是下一步的事情。为了让大家都有活干，我不得不停下来，把方案贴到wiki上，让其他小伙伴去实现。

看着挺荒谬的对吧？就像是你已经做好了一桌菜,却要假装只做了菜谱，然后把菜谱交给别人，让他们照着做一遍。

更荒谬的是，团队里对AI的接受程度差异巨大。有人觉得4.0生成的代码不准，坚持手写；有人则仅停留在对话生成，生成好坏看运气；而我因为用得多，已经积累了一套自己的提示词规则，生成的代码基本一把过。很多时候，看不过别人写或生成的代码（手艺人的强迫症），还得在告知的前提下，重新刷一遍。

最后的结果是：我既要做迭代规划、写故事卡、做方案,代码产出还比其他人的总和还多，甚至个别时候能多一倍。下项目后，我却被投诉了——理由是过度设计。

是不是挺无语？一个精通AI的人，方案都在脑子里，代码几个小时就能生成完，却要因为照顾团队的节奏刻意放慢速度。AI没能提效，也没能真正解决项目管理的问题。多做了没有奖励，反而可能给别人造成困扰（快速堆起来的代码，达到一定量级，即便正确，其他人也理解不了）。

这让我意识到一个很深刻的问题：**能不能提效是管理问题，能提效多少才和技术有一点关系。在管理问题没解决前，局部提效可能让整个系统承受不住。**

## 我正在被AI"退化"

更让我不安的，是我发现自己正在某种程度上"退化"。

**代码行数百行的时候**，25年3-5月份，我还会仔细看AI生成的代码。那时候更多是实现一个个小任务，一点一点完成需求，每次就几百行，我会习惯性地review一遍。

**代码行数千行的时候**，5月份后我就只看方案了。AI已经可以完整实现一个具体的任务，比如一整块数据映射代码。我只需要看它的方案是不是符合现有系统的机制，映射逻辑是否合理，生成的代码就不怎么看了。生成完直接测，有bug再喂进去让它修。

**代码行数万行的时候**，去年12月到现在，我开始大胆起来——不看方案了。如果98%的时候看完方案都是正确的，那是不是可以不看了？反正有问题也介入不了，直接丢进去让AI修。AI修不了我也修不了，因为代码量太大，而且很多领域我也不懂。

有时候测试都省了。加上SDD框架，配个Playwright模仿人做测试验证，准确度进一步抬高了。

你看，从看代码到看方案，再到不看方案，我对AI的依赖越来越深，对代码细节的把控越来越少。这算是进步还是退化？我自己也说不清楚。

就像开车，从手动挡到自动挡，再到自动驾驶。你确实不用踩离合器了，但你还算是在"开车"吗？

## AI真的是来帮我们的吗？

退一步，站在更大的视角来看，AI对整个行业的冲击可能比我们想象的要深远。

我们都说"AI辅助编程"，但现在的势头明摆着——AI不是冲着"辅助"来的，它是来"替代"的。

对于一家以盈利为目的的企业来说，选择很明确：AI比人有性价比，成本可控，产出稳定，24小时待命，好管理，可能还有税收减免。那为什么不缩减岗位呢？

可是缩减完岗位后，留下的人待遇上升了吗？没有。岗位少了，竞争多了，就开始竞价上岗了。你不干还有的是人干。AI技术一直迭代，学得很吃力就算了，技能的价值还在贬值。

总的来说，程序员群体的收入在下降。收入下降，消费就跟着降；消费降，企业营收就跟着降。这不就是通缩螺旋吗？

你可能会说，程序员只是个例，不能代表所有人。但恰恰相反，程序员可能只是开始。AI替代人这件事，在大多数行业都可能发生——客服、翻译、设计、会计、甚至律师和医生的一部分工作。

钱不会消失，它只是换了个地方。打工人手里的钱少了，会顺着AI的星际通道汇聚到巨头身上。而打工人就很容易陷入有工作没尊严的境地——毕竟房贷、车贷、老人、孩子，都是软肋。

社会要平衡，少了一些岗位就要多一些新的岗位出来。但目前能看到的是：AI能替代大量岗位，但AI能带来哪些新岗位？这个账严重失衡。

## 更可怕的，是对思想的侵蚀

经济上的冲击已经很严重了，但我觉得更深层的危险在于AI对我们思想的影响。

尤瓦尔·赫拉利在《人类简史》里说，人类社会本质上是由"共同想象"建构的。国家、货币、宗教、法律，这些都不是客观存在的东西，而是一群人共同相信的虚构概念。

以前社交媒体为了利润，会制造信息茧房，不断推送你喜欢的内容，让你沉迷其中看更多广告。比如你刷短视频，算法会识别你的喜好，然后不断给你推类似的内容。好在以前信息是有限的，即便你被困在茧房里，也能因为反复看到那几条内容的切片，或者发现证据链不足，而识别出问题跳出来。

但AI加持之后，事情就变得微妙了。

我们都说眼见为真，但AI生成的视频已经越来越像真的了。最近Seedance带来的震撼，你看了吗？视频生成技术的进步，意味着什么？

**意味着跟风产出内容的成本极速下降，速度急速上升。**

成本下降，就会有大量信息产出。大量信息要抓住眼球，就需要极端、差异化的言论。大量极端的言论以看不出真假的形态凭空出现。到时候的信息茧房可能不是简单的左派右派，而是108派，各有各的观点和"证据"，怎么刷都刷不完。哪里有漏洞，马上生成新的视频补上漏洞，你一旦掉进哪个坑都出不来。

言论的排序会不会进而发展成站队和冲突？这文化植立不要太容易。

你之所以相信有上下五千年的文化传承，是因为你从小到大看到的书、电影、纪录片都在讲这个故事。但当创建一系列证明上下五千年文化传承的信息变得非常轻松时，是不是就可以凭空给一群人构建起一个全新的文化认知？

这才是最可怕的。AI不仅在改变生产关系，还在改变我们对真实的感知，对历史的认知，对世界的理解。

## 我们该怎么办？

说了这么多，可能听起来有点悲观。但我不是想贩卖焦虑，而是想分享一些真实的感受和观察。

作为一个深度使用AI的人，我确实享受到了效率的提升，也确实感受到了一些不安。我看到系统性的问题——管理跟不上技术的进步，组织跟不上个体的提升。我也看到更大的危机——经济的失衡，思想的侵蚀。

但我也相信，技术本身是中性的，关键在于我们怎么用它，怎么应对它带来的变化。

也许我们需要重新思考工作的意义，重新定义人的价值。也许我们需要建立新的社会契约，让技术进步的红利能够更公平地分配。也许我们需要更警惕地看待信息，培养批判性思维，不被算法和AI牵着鼻子走。

这些问题没有标准答案。但有一点是确定的：变化已经发生，而且会持续加速。我们唯一能做的，就是睁大眼睛，保持清醒，在变化中找到自己的位置。

---

**如果今天你只记得一句话，那就是：**

_AI不是问题，问题是我们还没想好如何与AI共存。_
